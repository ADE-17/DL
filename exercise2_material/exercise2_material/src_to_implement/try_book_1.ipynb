{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "from Layers import Base\n",
    "from scipy import signal\n",
    "from Layers import Flatten\n",
    "class L2Loss:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_tensor = None\n",
    "\n",
    "    def forward(self, input_tensor, label_tensor):\n",
    "        self.input_tensor = input_tensor\n",
    "        return np.sum(np.square(input_tensor - label_tensor))\n",
    "\n",
    "    def backward(self, label_tensor):\n",
    "        return 2*np.subtract(self.input_tensor, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.signal import correlate, correlate2d\n",
    "from Layers.Base import BaseLayer\n",
    "class Conv(Base.BaseLayer):\n",
    "    def __init__(self, stride_shape, convolution_shape, num_kernels):\n",
    "\n",
    "        super().__init__()\n",
    "        self.stride_shape = stride_shape\n",
    "        self.convolution_shape = convolution_shape\n",
    "        self.num_kernels = num_kernels\n",
    "\n",
    "        if len(convolution_shape)==3:\n",
    "            self.weights = np.random.rand(num_kernels, convolution_shape[0], convolution_shape[1], convolution_shape[2])\n",
    "        elif len(convolution_shape)==2:\n",
    "            self.weights = np.random.rand(num_kernels, convolution_shape[0], convolution_shape[1])\n",
    "            \n",
    "        self.bias = np.random.rand(num_kernels)\n",
    "        self._optimizer = None \n",
    "        self._bias_optimizer = None\n",
    "        self._gradient_weights = np.zeros_like(self.weights)\n",
    "        self._gradient_bias = None\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        self.input_tensor = input_tensor\n",
    "        \n",
    "        #initialize zeros, based on input tensor, number of kernels, and the stride shape.       \n",
    "        if len(self.convolution_shape) == 3: #If the convolution shape is 3D \n",
    "            result = np.zeros((input_tensor.shape[0], \n",
    "                               self.num_kernels, \n",
    "                               int(np.ceil(input_tensor.shape[2]/self.stride_shape[0])),\n",
    "                               int(np.ceil(input_tensor.shape[3]/self.stride_shape[1]))))\n",
    "            #result.shape = (batch_size, num_kernels, output_height, output_width)      \n",
    "        elif len(self.convolution_shape) == 2: #If the convolution shape is 2D\n",
    "            result = np.zeros((input_tensor.shape[0], \n",
    "                               self.num_kernels, \n",
    "                               int(np.ceil(input_tensor.shape[2]/self.stride_shape[0]))))\n",
    "            #result.shape = (batch_size, num_kernels, output_height)\n",
    "            \n",
    "        result = [] #stores results of convolution layer\n",
    "        \n",
    "        for batch in range(input_tensor.shape[0]): # Iterate over input tensor\n",
    "            result_batch = [] #stores results of convolution layer of that batch\n",
    "            \n",
    "            for output_channel in range(self.weights.shape[0]): # Iterate over each kernel's output channel\n",
    "                \n",
    "                conv_sum = 0 # track sum of convolutions\n",
    "                \n",
    "                # Iterate over each kernel's input channel\n",
    "                for input_channel in range(self.weights.shape[1]): #Iterate over each input channel\n",
    "                    #conv_out = stores result for each input channel\n",
    "                    conv_out = signal.correlate(input_tensor[batch, input_channel],\n",
    "                                                self.weights[output_channel, input_channel], \n",
    "                                                mode='same', method='direct') # Perform convolution\n",
    "                    \n",
    "                    conv_sum += conv_out \n",
    "\n",
    "                # Check convolution shape after processing all input channels\n",
    "                \n",
    "                # If 3D, select every stride_shape[0]-th element along the height \n",
    "                # and every stride_shape[1]-th element along the width of the conv_sum\n",
    "                if len(self.convolution_shape) == 3:\n",
    "                    conv_sum = conv_sum[::self.stride_shape[0], ::self.stride_shape[1]]\n",
    "                # If 2D, subsample along the height dimension\n",
    "                elif len(self.convolution_shape) == 2:\n",
    "                    conv_sum = conv_sum[::self.stride_shape[0]]\n",
    "   \n",
    "                result_batch.append(conv_sum + self.bias[output_channel]) # Add the bias value corresponding to the current output channel\n",
    "\n",
    "            result.append(result_batch) # Append result_batch to the final result\n",
    "\n",
    "        output_tensor = np.array(result) # Convert to numpy array\n",
    "        \n",
    "        self.output_shape  = output_tensor.shape # used in backward\n",
    "        \n",
    "        return output_tensor\n",
    "    \n",
    "    def backward(self, error_tensor):\n",
    "        \n",
    "        self.error_tensor_reshaped = error_tensor.reshape(self.output_shape) #reshaping to match shape of output_tensor\n",
    "        \n",
    "        if len(self.convolution_shape) == 2: # check for 2D\n",
    "            self.input_tensor = self.input_tensor[:, :, :, np.newaxis]\n",
    "        \n",
    "        # Initialize with zeros, to store upsampled error tensor\n",
    "        self.upsampled_error_tensor = np.zeros((self.input_tensor.shape[0], self.num_kernels, *self.input_tensor.shape[2:]))\n",
    "        \n",
    "        #Initialize return tensor to return gradient weights\n",
    "        return_tensor = np.zeros(self.input_tensor.shape)\n",
    "        \n",
    "        # Initialize with zero, stores input tensor after padding\n",
    "        self.padded_input_tensor = np.zeros((*self.input_tensor.shape[:2], self.input_tensor.shape[2] + self.convolution_shape[1] - 1,\n",
    "                                   self.input_tensor.shape[3] + self.convolution_shape[2] - 1))\n",
    "        \n",
    "        # Initialize gradient bias with zeros, will store the gradient with respect to the bias terms \n",
    "        self.gradient_bias = np.zeros(self.num_kernels)\n",
    "        \n",
    "        # Initialize gradient weights with zeros, will store the gradient with respect to the weights\n",
    "        self.gradient_weights = np.zeros(self.weights.shape)\n",
    "\n",
    "        # padding along the height dimension (verticle) of the input tensor\n",
    "        padding_verticle = int(np.floor(self.convolution_shape[2] / 2))  \n",
    "        \n",
    "        # padding along the width dimension (horizontal) of the input tensor\n",
    "        padding_horizontal = int(np.floor(self.convolution_shape[1] / 2))\n",
    "\n",
    "        # Upsampling and filling unsampled error tensor\n",
    "        for batch in range(self.upsampled_error_tensor.shape[0]):\n",
    "            for kernel in range(self.upsampled_error_tensor.shape[1]):\n",
    "                # gradient with respect to the bias\n",
    "                self.gradient_bias[kernel] += np.sum(error_tensor[batch, kernel, :])\n",
    "\n",
    "                for h in range(self.error_tensor_reshaped.shape[2]):\n",
    "                    for w in range(self.error_tensor_reshaped.shape[3]):\n",
    "                        self.upsampled_error_tensor[batch, kernel, h * self.stride_shape[0], w * self.stride_shape[1]] = self.error_tensor_reshaped[batch, kernel, h, w]  \n",
    "\n",
    "                for channel in range(self.input_tensor.shape[1]):  \n",
    "                    return_tensor[batch, channel, :] += signal.convolve2d(self.upsampled_error_tensor[batch, kernel, :], self.weights[kernel, channel, :], 'same')  # zero padding\n",
    "\n",
    "            # Delete the padding\n",
    "            for n in range(self.input_tensor.shape[1]):\n",
    "                for h in range(self.padded_input_tensor.shape[2]):\n",
    "                    for w in range(self.padded_input_tensor.shape[3]):\n",
    "                        if (h > padding_horizontal - 1) and (h < self.input_tensor.shape[2] + padding_horizontal):\n",
    "                            if (w > padding_verticle - 1) and (w < self.input_tensor.shape[3] + padding_verticle):\n",
    "                                self.padded_input_tensor[batch, n, h, w] = self.input_tensor[batch, n, h - padding_horizontal, w - padding_verticle]\n",
    "\n",
    "            for kernel in range(self.num_kernels):\n",
    "                for c in range(self.input_tensor.shape[1]):\n",
    "                    # convolution of the upsampled error tensor with the padded input tensor\n",
    "                    self.gradient_weights[kernel, c, :] += correlate2d(self.padded_input_tensor[batch, c, :], self.upsampled_error_tensor[batch, kernel, :], 'valid')  # valid padding\n",
    "\n",
    "\n",
    "        if self._optimizer is not None:\n",
    "            self.weights = self._optimizer.weights.calculate_update(self.weights, self.gradient_weights)\n",
    "            self.bias = self._optimizer.bias.calculate_update(self.bias, self.gradient_bias)\n",
    "        \n",
    "        # In case of 2D input\n",
    "        if len(self.convolution_shape) == 2:\n",
    "            return_tensor = return_tensor.squeeze(axis = 3) \n",
    "            \n",
    "        return return_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestInitializer:\n",
    "    def __init__(self):\n",
    "        self.fan_in = None\n",
    "        self.fan_out = None\n",
    "\n",
    "    def initialize(self, shape, fan_in, fan_out):\n",
    "        self.fan_in = fan_in\n",
    "        self.fan_out = fan_out\n",
    "        weights = np.zeros((1, 3, 3, 3))\n",
    "        weights[0, 1, 1, 1] = 1\n",
    "        return weights\n",
    "    \n",
    "batch_size = 2\n",
    "input_shape = (3, 10, 14)\n",
    "input_size = 14 * 10 * 3\n",
    "uneven_input_shape = (3, 11, 15)\n",
    "uneven_input_size = 15 * 11 * 3\n",
    "spatial_input_shape = np.prod(input_shape[1:])\n",
    "kernel_shape = (3, 5, 8)\n",
    "num_kernels = 4\n",
    "hidden_channels = 3\n",
    "\n",
    "categories = 105\n",
    "label_tensor = np.zeros([batch_size, categories])\n",
    "for i in range(batch_size):\n",
    "    label_tensor[i, np.random.randint(0, categories)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Conv((1, 1), kernel_shape, num_kernels)\n",
    "input_tensor = np.array(range(np.prod(input_shape) * batch_size), dtype=float)\n",
    "input_tensor = input_tensor.reshape(batch_size, *input_shape)\n",
    "output_tensor = conv.forward(input_tensor)\n",
    "error_tensor = conv.backward(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10281588892389149"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
